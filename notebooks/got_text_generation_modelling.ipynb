{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Game ot thrones\n",
    "## Text Generation\n",
    "<hr>\n",
    "\n",
    "### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import randint\n",
    "from scipy import sparse\n",
    "\n",
    "from pickle import dump\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import plot_model\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    "from keras.utils import pad_sequences"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('../datasets/got1_sequences.txt', 'r')\n",
    "# read all text\n",
    "txtDataset = file.read()\n",
    "# close the file\n",
    "file.close()\n",
    "lstSequences = txtDataset.split('\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode Sequences\n",
    "The word embedding layer expects input sequences to be comprised of integers. We can map\n",
    "each word in our vocabulary to a unique integer and encode our input sequences. Later, when\n",
    "we make predictions, we can convert the prediction to numbers and look up their associated\n",
    "words in the same mapping. To do this encoding, we will use the Tokenizer class in the Keras\n",
    "API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'saw them gared said if he says they are dead thats proof enough for me will had known they would drag him into the quarrel sooner or later he wished it had been later rather than sooner my mother told me that dead men sing no songs he put in my'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstSequences[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(lstSequences)\n",
    "sequences = tokenizer.texts_to_sequences(lstSequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4,\n",
       " 1116,\n",
       " 5,\n",
       " 1741,\n",
       " 1323,\n",
       " 46,\n",
       " 5,\n",
       " 4,\n",
       " 1032,\n",
       " 5,\n",
       " 602,\n",
       " 2,\n",
       " 248,\n",
       " 65,\n",
       " 3339,\n",
       " 11938,\n",
       " 11938,\n",
       " 2403,\n",
       " 11940,\n",
       " 63,\n",
       " 181,\n",
       " 1367,\n",
       " 57,\n",
       " 1096,\n",
       " 1207,\n",
       " 16,\n",
       " 1,\n",
       " 791,\n",
       " 252,\n",
       " 3,\n",
       " 1095,\n",
       " 228,\n",
       " 126,\n",
       " 32,\n",
       " 1,\n",
       " 2138,\n",
       " 55,\n",
       " 148,\n",
       " 59,\n",
       " 1,\n",
       " 148,\n",
       " 2012,\n",
       " 10,\n",
       " 40,\n",
       " 1322,\n",
       " 889,\n",
       " 143,\n",
       " 18,\n",
       " 230,\n",
       " 1,\n",
       " 2580]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of vocabulary : 11941\n"
     ]
    }
   ],
   "source": [
    "vocab_size=len(tokenizer.word_index) + 1\n",
    "print (f'Size of vocabulary : {vocab_size}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have encoded the input sequences, we need to separate them into input (X) and\n",
    "output (y) elements, remember in the previos stage I split the text into a 50 words secuence + 1 to be the target label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#original script \n",
    "sequences = np.array(sequences,dtype=object)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>1116</td>\n",
       "      <td>5</td>\n",
       "      <td>1741</td>\n",
       "      <td>1323</td>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1032</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>40</td>\n",
       "      <td>1322</td>\n",
       "      <td>889</td>\n",
       "      <td>143</td>\n",
       "      <td>18</td>\n",
       "      <td>230</td>\n",
       "      <td>1</td>\n",
       "      <td>2580</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1116</td>\n",
       "      <td>5</td>\n",
       "      <td>1741</td>\n",
       "      <td>1323</td>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1032</td>\n",
       "      <td>5</td>\n",
       "      <td>602</td>\n",
       "      <td>...</td>\n",
       "      <td>1322</td>\n",
       "      <td>889</td>\n",
       "      <td>143</td>\n",
       "      <td>18</td>\n",
       "      <td>230</td>\n",
       "      <td>1</td>\n",
       "      <td>2580</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>1741</td>\n",
       "      <td>1323</td>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1032</td>\n",
       "      <td>5</td>\n",
       "      <td>602</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>889</td>\n",
       "      <td>143</td>\n",
       "      <td>18</td>\n",
       "      <td>230</td>\n",
       "      <td>1</td>\n",
       "      <td>2580</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1741</td>\n",
       "      <td>1323</td>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1032</td>\n",
       "      <td>5</td>\n",
       "      <td>602</td>\n",
       "      <td>2</td>\n",
       "      <td>248</td>\n",
       "      <td>...</td>\n",
       "      <td>143</td>\n",
       "      <td>18</td>\n",
       "      <td>230</td>\n",
       "      <td>1</td>\n",
       "      <td>2580</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>274</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1323</td>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1032</td>\n",
       "      <td>5</td>\n",
       "      <td>602</td>\n",
       "      <td>2</td>\n",
       "      <td>248</td>\n",
       "      <td>65</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>230</td>\n",
       "      <td>1</td>\n",
       "      <td>2580</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>274</td>\n",
       "      <td>1096</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293481</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>190</td>\n",
       "      <td>9</td>\n",
       "      <td>102</td>\n",
       "      <td>3337</td>\n",
       "      <td>340</td>\n",
       "      <td>1005</td>\n",
       "      <td>11937</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>187</td>\n",
       "      <td>1</td>\n",
       "      <td>157</td>\n",
       "      <td>125</td>\n",
       "      <td>744</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293482</th>\n",
       "      <td>9</td>\n",
       "      <td>190</td>\n",
       "      <td>9</td>\n",
       "      <td>102</td>\n",
       "      <td>3337</td>\n",
       "      <td>340</td>\n",
       "      <td>1005</td>\n",
       "      <td>11937</td>\n",
       "      <td>31</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>187</td>\n",
       "      <td>1</td>\n",
       "      <td>157</td>\n",
       "      <td>125</td>\n",
       "      <td>744</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1742</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293483</th>\n",
       "      <td>190</td>\n",
       "      <td>9</td>\n",
       "      <td>102</td>\n",
       "      <td>3337</td>\n",
       "      <td>340</td>\n",
       "      <td>1005</td>\n",
       "      <td>11937</td>\n",
       "      <td>31</td>\n",
       "      <td>99</td>\n",
       "      <td>285</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>157</td>\n",
       "      <td>125</td>\n",
       "      <td>744</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1742</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293484</th>\n",
       "      <td>9</td>\n",
       "      <td>102</td>\n",
       "      <td>3337</td>\n",
       "      <td>340</td>\n",
       "      <td>1005</td>\n",
       "      <td>11937</td>\n",
       "      <td>31</td>\n",
       "      <td>99</td>\n",
       "      <td>285</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>157</td>\n",
       "      <td>125</td>\n",
       "      <td>744</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1742</td>\n",
       "      <td>5</td>\n",
       "      <td>536</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293485</th>\n",
       "      <td>102</td>\n",
       "      <td>3337</td>\n",
       "      <td>340</td>\n",
       "      <td>1005</td>\n",
       "      <td>11937</td>\n",
       "      <td>31</td>\n",
       "      <td>99</td>\n",
       "      <td>285</td>\n",
       "      <td>2</td>\n",
       "      <td>5983</td>\n",
       "      <td>...</td>\n",
       "      <td>125</td>\n",
       "      <td>744</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1742</td>\n",
       "      <td>5</td>\n",
       "      <td>536</td>\n",
       "      <td>67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>293486 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0     1     2     3      4      5      6      7      8     9   ...  \\\n",
       "0          4  1116     5  1741   1323     46      5      4   1032     5  ...   \n",
       "1       1116     5  1741  1323     46      5      4   1032      5   602  ...   \n",
       "2          5  1741  1323    46      5      4   1032      5    602     2  ...   \n",
       "3       1741  1323    46     5      4   1032      5    602      2   248  ...   \n",
       "4       1323    46     5     4   1032      5    602      2    248    65  ...   \n",
       "...      ...   ...   ...   ...    ...    ...    ...    ...    ...   ...  ...   \n",
       "293481     3     9   190     9    102   3337    340   1005  11937    31  ...   \n",
       "293482     9   190     9   102   3337    340   1005  11937     31    99  ...   \n",
       "293483   190     9   102  3337    340   1005  11937     31     99   285  ...   \n",
       "293484     9   102  3337   340   1005  11937     31     99    285     2  ...   \n",
       "293485   102  3337   340  1005  11937     31     99    285      2  5983  ...   \n",
       "\n",
       "          43    44   45    46    47    48    49    50  51  52  \n",
       "0         40  1322  889   143    18   230     1  2580 NaN NaN  \n",
       "1       1322   889  143    18   230     1  2580     5 NaN NaN  \n",
       "2        889   143   18   230     1  2580     5     4 NaN NaN  \n",
       "3        143    18  230     1  2580     5     4   274 NaN NaN  \n",
       "4         18   230    1  2580     5     4   274  1096 NaN NaN  \n",
       "...      ...   ...  ...   ...   ...   ...   ...   ...  ..  ..  \n",
       "293481     5   187    1   157   125   744    18     1 NaN NaN  \n",
       "293482   187     1  157   125   744    18     1  1742 NaN NaN  \n",
       "293483     1   157  125   744    18     1  1742     5 NaN NaN  \n",
       "293484   157   125  744    18     1  1742     5   536 NaN NaN  \n",
       "293485   125   744   18     1  1742     5   536    67 NaN NaN  \n",
       "\n",
       "[293486 rows x 53 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#option 3. using pandas\n",
    "dfsequences = pd.DataFrame(sequences, index=None)\n",
    "dfsequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>1116</td>\n",
       "      <td>5</td>\n",
       "      <td>1741</td>\n",
       "      <td>1323</td>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1032</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>148</td>\n",
       "      <td>2012</td>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>1322</td>\n",
       "      <td>889</td>\n",
       "      <td>143</td>\n",
       "      <td>18</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1116</td>\n",
       "      <td>5</td>\n",
       "      <td>1741</td>\n",
       "      <td>1323</td>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1032</td>\n",
       "      <td>5</td>\n",
       "      <td>602</td>\n",
       "      <td>...</td>\n",
       "      <td>148</td>\n",
       "      <td>2012</td>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>1322</td>\n",
       "      <td>889</td>\n",
       "      <td>143</td>\n",
       "      <td>18</td>\n",
       "      <td>230</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>1741</td>\n",
       "      <td>1323</td>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1032</td>\n",
       "      <td>5</td>\n",
       "      <td>602</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2012</td>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>1322</td>\n",
       "      <td>889</td>\n",
       "      <td>143</td>\n",
       "      <td>18</td>\n",
       "      <td>230</td>\n",
       "      <td>1</td>\n",
       "      <td>2580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1741</td>\n",
       "      <td>1323</td>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1032</td>\n",
       "      <td>5</td>\n",
       "      <td>602</td>\n",
       "      <td>2</td>\n",
       "      <td>248</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>1322</td>\n",
       "      <td>889</td>\n",
       "      <td>143</td>\n",
       "      <td>18</td>\n",
       "      <td>230</td>\n",
       "      <td>1</td>\n",
       "      <td>2580</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1323</td>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1032</td>\n",
       "      <td>5</td>\n",
       "      <td>602</td>\n",
       "      <td>2</td>\n",
       "      <td>248</td>\n",
       "      <td>65</td>\n",
       "      <td>...</td>\n",
       "      <td>40</td>\n",
       "      <td>1322</td>\n",
       "      <td>889</td>\n",
       "      <td>143</td>\n",
       "      <td>18</td>\n",
       "      <td>230</td>\n",
       "      <td>1</td>\n",
       "      <td>2580</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293481</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>190</td>\n",
       "      <td>9</td>\n",
       "      <td>102</td>\n",
       "      <td>3337</td>\n",
       "      <td>340</td>\n",
       "      <td>1005</td>\n",
       "      <td>11937</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>137</td>\n",
       "      <td>101</td>\n",
       "      <td>11</td>\n",
       "      <td>1809</td>\n",
       "      <td>5</td>\n",
       "      <td>187</td>\n",
       "      <td>1</td>\n",
       "      <td>157</td>\n",
       "      <td>125</td>\n",
       "      <td>744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293482</th>\n",
       "      <td>9</td>\n",
       "      <td>190</td>\n",
       "      <td>9</td>\n",
       "      <td>102</td>\n",
       "      <td>3337</td>\n",
       "      <td>340</td>\n",
       "      <td>1005</td>\n",
       "      <td>11937</td>\n",
       "      <td>31</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>101</td>\n",
       "      <td>11</td>\n",
       "      <td>1809</td>\n",
       "      <td>5</td>\n",
       "      <td>187</td>\n",
       "      <td>1</td>\n",
       "      <td>157</td>\n",
       "      <td>125</td>\n",
       "      <td>744</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293483</th>\n",
       "      <td>190</td>\n",
       "      <td>9</td>\n",
       "      <td>102</td>\n",
       "      <td>3337</td>\n",
       "      <td>340</td>\n",
       "      <td>1005</td>\n",
       "      <td>11937</td>\n",
       "      <td>31</td>\n",
       "      <td>99</td>\n",
       "      <td>285</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>1809</td>\n",
       "      <td>5</td>\n",
       "      <td>187</td>\n",
       "      <td>1</td>\n",
       "      <td>157</td>\n",
       "      <td>125</td>\n",
       "      <td>744</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293484</th>\n",
       "      <td>9</td>\n",
       "      <td>102</td>\n",
       "      <td>3337</td>\n",
       "      <td>340</td>\n",
       "      <td>1005</td>\n",
       "      <td>11937</td>\n",
       "      <td>31</td>\n",
       "      <td>99</td>\n",
       "      <td>285</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1809</td>\n",
       "      <td>5</td>\n",
       "      <td>187</td>\n",
       "      <td>1</td>\n",
       "      <td>157</td>\n",
       "      <td>125</td>\n",
       "      <td>744</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293485</th>\n",
       "      <td>102</td>\n",
       "      <td>3337</td>\n",
       "      <td>340</td>\n",
       "      <td>1005</td>\n",
       "      <td>11937</td>\n",
       "      <td>31</td>\n",
       "      <td>99</td>\n",
       "      <td>285</td>\n",
       "      <td>2</td>\n",
       "      <td>5983</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>187</td>\n",
       "      <td>1</td>\n",
       "      <td>157</td>\n",
       "      <td>125</td>\n",
       "      <td>744</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1742</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>293486 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0     1     2     3      4      5      6      7      8     9   ...  \\\n",
       "0          4  1116     5  1741   1323     46      5      4   1032     5  ...   \n",
       "1       1116     5  1741  1323     46      5      4   1032      5   602  ...   \n",
       "2          5  1741  1323    46      5      4   1032      5    602     2  ...   \n",
       "3       1741  1323    46     5      4   1032      5    602      2   248  ...   \n",
       "4       1323    46     5     4   1032      5    602      2    248    65  ...   \n",
       "...      ...   ...   ...   ...    ...    ...    ...    ...    ...   ...  ...   \n",
       "293481     3     9   190     9    102   3337    340   1005  11937    31  ...   \n",
       "293482     9   190     9   102   3337    340   1005  11937     31    99  ...   \n",
       "293483   190     9   102  3337    340   1005  11937     31     99   285  ...   \n",
       "293484     9   102  3337   340   1005  11937     31     99    285     2  ...   \n",
       "293485   102  3337   340  1005  11937     31     99    285      2  5983  ...   \n",
       "\n",
       "          39    40    41    42    43    44   45    46    47    48  \n",
       "0          1   148  2012    10    40  1322  889   143    18   230  \n",
       "1        148  2012    10    40  1322   889  143    18   230     1  \n",
       "2       2012    10    40  1322   889   143   18   230     1  2580  \n",
       "3         10    40  1322   889   143    18  230     1  2580     5  \n",
       "4         40  1322   889   143    18   230    1  2580     5     4  \n",
       "...      ...   ...   ...   ...   ...   ...  ...   ...   ...   ...  \n",
       "293481   137   101    11  1809     5   187    1   157   125   744  \n",
       "293482   101    11  1809     5   187     1  157   125   744    18  \n",
       "293483    11  1809     5   187     1   157  125   744    18     1  \n",
       "293484  1809     5   187     1   157   125  744    18     1  1742  \n",
       "293485     5   187     1   157   125   744   18     1  1742     5  \n",
       "\n",
       "[293486 rows x 49 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = dfsequences.iloc[:,0:49]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = dfsequences.iloc[:,50]\n",
    "y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = dfsequences.iloc[:,0:49].values\n",
    "y = dfsequences.iloc[:,50].values\n",
    "y = to_categorical(y, num_classes=vocab_size)\n",
    "#y= sparse.csr_matrix((np.ones(len(y)), (np.arange(len(y)), y)), shape=(len(y), vocab_size))\n",
    "seq_length = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(293486, 11941)\n"
     ]
    }
   ],
   "source": [
    "print(y.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 50, input_length=seq_length))\n",
    "model.add(LSTM(100, return_sequences=True))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 49, 50)            597050    \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 49, 100)           60400     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 100)               80400     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 11941)             1206041   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,953,991\n",
      "Trainable params: 1,953,991\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "# compile network\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# summarize defined model\n",
    "model.summary()\n",
    "plot_model(model, to_file='../assets/model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2293/2293 [==============================] - 474s 205ms/step - loss: 5.0359 - accuracy: 0.1167\n",
      "Epoch 2/20\n",
      "2293/2293 [==============================] - 487s 213ms/step - loss: 4.9001 - accuracy: 0.1217\n",
      "Epoch 3/20\n",
      "2293/2293 [==============================] - 516s 225ms/step - loss: 4.8353 - accuracy: 0.1275\n",
      "Epoch 4/20\n",
      "2293/2293 [==============================] - 502s 219ms/step - loss: 4.7869 - accuracy: 0.1322\n",
      "Epoch 5/20\n",
      "2293/2293 [==============================] - 473s 206ms/step - loss: 4.7445 - accuracy: 0.1363\n",
      "Epoch 6/20\n",
      "2293/2293 [==============================] - 481s 210ms/step - loss: 4.7074 - accuracy: 0.1401\n",
      "Epoch 7/20\n",
      "2293/2293 [==============================] - 474s 207ms/step - loss: 4.6717 - accuracy: 0.1434\n",
      "Epoch 8/20\n",
      "2293/2293 [==============================] - 463s 202ms/step - loss: 4.6379 - accuracy: 0.1461\n",
      "Epoch 9/20\n",
      "2293/2293 [==============================] - 468s 204ms/step - loss: 4.6051 - accuracy: 0.1490\n",
      "Epoch 10/20\n",
      "2293/2293 [==============================] - 443s 193ms/step - loss: 4.5744 - accuracy: 0.1524\n",
      "Epoch 11/20\n",
      "2293/2293 [==============================] - 442s 193ms/step - loss: 4.5465 - accuracy: 0.1546\n",
      "Epoch 12/20\n",
      "2293/2293 [==============================] - 461s 201ms/step - loss: 4.5143 - accuracy: 0.1584\n",
      "Epoch 13/20\n",
      "2293/2293 [==============================] - 468s 204ms/step - loss: 4.4879 - accuracy: 0.1603\n",
      "Epoch 14/20\n",
      "2293/2293 [==============================] - 465s 203ms/step - loss: 4.4594 - accuracy: 0.1637\n",
      "Epoch 15/20\n",
      "2293/2293 [==============================] - 466s 203ms/step - loss: 4.4330 - accuracy: 0.1667\n",
      "Epoch 16/20\n",
      "2293/2293 [==============================] - 436s 190ms/step - loss: 4.4056 - accuracy: 0.1695\n",
      "Epoch 17/20\n",
      "2293/2293 [==============================] - 427s 186ms/step - loss: 4.3804 - accuracy: 0.1715\n",
      "Epoch 18/20\n",
      "2293/2293 [==============================] - 444s 193ms/step - loss: 4.3549 - accuracy: 0.1748\n",
      "Epoch 19/20\n",
      "2293/2293 [==============================] - 481s 210ms/step - loss: 4.3299 - accuracy: 0.1772\n",
      "Epoch 20/20\n",
      "2293/2293 [==============================] - 469s 204ms/step - loss: 4.3058 - accuracy: 0.1798\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x254b7f18f40>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model\n",
    "model.fit(X, y, batch_size=128, epochs=20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to file\n",
    "model.save('../model/model_got.h5')\n",
    "# save the tokenizer\n",
    "dump(tokenizer, open('../model/tokenizer_got.pkl', 'wb'))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toward harrenhal burning as he goes grim and grimmer thought catelyn it was worse than shed imagined you mean to meet him here she asked if he comes so far but no one thinks he will robb said ive sent word to howland reed fathers old friend at greywater watch if\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# select a seed text whatever\n",
    "seed_text = lstSequences[randint(0,len(lstSequences))]\n",
    "print(seed_text + '\\n')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to predict I need to encode selected line with the same tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodedLine = tokenizer.texts_to_sequences([seed_text])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed line : on his face watching heward turn over tiles and enjoying the view page 000 ned paused at the foot of the stair and pulled on his gloves its time we took our leave my business here is done heward lurched to his feet hurriedly gathering up his things as you will\n",
      "encoded line : [24, 7, 88, 679, 3320, 743, 89, 9611, 2, 4535, 1, 2201, 67, 77, 51, 2021, 23, 1, 566, 5, 1, 1736, 2, 366, 24, 7, 1906, 99, 101, 63, 119, 195, 264, 28, 1117, 86, 27, 225, 3320, 1941, 3, 7, 190, 3295, 2223, 50, 7, 377, 16, 10, 43]\n"
     ]
    }
   ],
   "source": [
    "print(f'seed line : {seed_text}')\n",
    "print(f'encoded line : {encodedLine}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step\n",
      "the index predicted [55] in iteration number 0\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "the index predicted [6355] in iteration number 1\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "the index predicted [41] in iteration number 2\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "the index predicted [1] in iteration number 3\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "the index predicted [5] in iteration number 4\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "the index predicted [55] in iteration number 5\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "the index predicted [2947] in iteration number 6\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "the index predicted [14] in iteration number 7\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "the index predicted [10] in iteration number 8\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "the index predicted [3] in iteration number 9\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "the index predicted [4] in iteration number 10\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "the index predicted [5] in iteration number 11\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "the index predicted [1556] in iteration number 12\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "the index predicted [2011] in iteration number 13\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "the index predicted [903] in iteration number 14\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "the index predicted [1] in iteration number 15\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "the index predicted [5] in iteration number 16\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "the index predicted [5] in iteration number 17\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "the index predicted [1] in iteration number 18\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "the index predicted [8] in iteration number 19\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "the index predicted [5] in iteration number 20\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "the index predicted [1] in iteration number 21\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "the index predicted [8] in iteration number 22\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "the index predicted [5] in iteration number 23\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "the index predicted [1] in iteration number 24\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "the index predicted [8] in iteration number 25\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "the index predicted [2423] in iteration number 26\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "the index predicted [2937] in iteration number 27\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "the index predicted [20] in iteration number 28\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "the index predicted [1] in iteration number 29\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "the index predicted [5] in iteration number 30\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "the index predicted [5] in iteration number 31\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "the index predicted [497] in iteration number 32\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "the index predicted [5299] in iteration number 33\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "the index predicted [2] in iteration number 34\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "the index predicted [2756] in iteration number 35\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "the index predicted [1] in iteration number 36\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "the index predicted [5853] in iteration number 37\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "the index predicted [1] in iteration number 38\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "the index predicted [4424] in iteration number 39\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "the index predicted [118] in iteration number 40\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "the index predicted [1] in iteration number 41\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "the index predicted [5] in iteration number 42\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "the index predicted [2894] in iteration number 43\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "the index predicted [52] in iteration number 44\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "the index predicted [3747] in iteration number 45\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "the index predicted [655] in iteration number 46\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "the index predicted [2785] in iteration number 47\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "the index predicted [4086] in iteration number 48\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "the index predicted [4] in iteration number 49\n"
     ]
    }
   ],
   "source": [
    "lstResult = list()\n",
    "in_text = seed_text\n",
    "# generate a fixed number of words, 50 because is the lenght of line\n",
    "for iteration in range(50): \n",
    "    # encode the text as integer\n",
    "    encodedLine = tokenizer.texts_to_sequences([in_text])[0]\n",
    "    # truncate sequences to a fixed length, maxlen= 50 -1\n",
    "    encodedLine = pad_sequences([encodedLine], maxlen=49, truncating='pre')\n",
    "    \n",
    "    # predict probabilities for each word\n",
    "    prediction = np.argmax(model.predict(encodedLine), axis=-1)\n",
    "    print(f'the index predicted {prediction} in iteration number {iteration}')\n",
    "    \n",
    "    # map predicted word index to word\n",
    "    out_word = ''\n",
    "    out_word = {i for i in tokenizer.word_index if tokenizer.word_index[i]==prediction}\n",
    "    \n",
    "    predictedWord = out_word.pop()\n",
    "    in_text += ' ' + predictedWord\n",
    "    lstResult.append(predictedWord)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "are prickly me the of are beloved i you to a of lives stewards eat the of of the was of the was of the was speaks escaped said the of of eyrie unhappy and grant the prowess the insolence come the of gerold out garrons dozen bows horsemen a\n"
     ]
    }
   ],
   "source": [
    "#finally I print the resultant line\n",
    "print(' '.join(lstResult))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The poor accuracy affect the quality of generated text. I think I'm going to change the text preprocessing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
